{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# EVA 7 - Assignment 2.5 - Python 101 + Pytorch 101\n\n## Create a NN to add random number to number detected from MNIST image","metadata":{"execution":{"iopub.status.busy":"2021-10-12T09:22:20.576972Z","iopub.execute_input":"2021-10-12T09:22:20.578712Z","iopub.status.idle":"2021-10-12T09:22:20.59746Z","shell.execute_reply.started":"2021-10-12T09:22:20.57863Z","shell.execute_reply":"2021-10-12T09:22:20.596659Z"}}},{"cell_type":"markdown","source":"### Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:01.669427Z","iopub.execute_input":"2021-10-13T06:42:01.66995Z","iopub.status.idle":"2021-10-13T06:42:08.419764Z","shell.execute_reply.started":"2021-10-13T06:42:01.669817Z","shell.execute_reply":"2021-10-13T06:42:08.418902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.utils.data import DataLoader\nfrom torchsummary import summary\n\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:08.426963Z","iopub.execute_input":"2021-10-13T06:42:08.427307Z","iopub.status.idle":"2021-10-13T06:42:09.036487Z","shell.execute_reply.started":"2021-10-13T06:42:08.42727Z","shell.execute_reply":"2021-10-13T06:42:09.035749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for CUDA - Always use GPU if available","metadata":{}},{"cell_type":"code","source":"# check if cuda is available\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:09.037842Z","iopub.execute_input":"2021-10-13T06:42:09.038099Z","iopub.status.idle":"2021-10-13T06:42:09.061567Z","shell.execute_reply.started":"2021-10-13T06:42:09.038066Z","shell.execute_reply":"2021-10-13T06:42:09.060547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import MNIST Dataset, Add Random numbers & Sums to create Test and Train Datasets","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(1) ## Define seed so generation of random numbers remains same across multiple runs\nbatch_size = 128 ## Define batch size\nkwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n\n\nclass RandomMNISTDataset(Dataset):\n    def __init__(self, MNISTDataset):\n        self.MNISTDataset = MNISTDataset\n        \n    def __getitem__(self, index):\n        image = self.MNISTDataset[index][0]\n        label = self.MNISTDataset[index][1]\n        randNum = torch.randint(0,9, (1,1))\n        randNum_oneHot = F.one_hot(randNum, num_classes=10).type(torch.float32)\n        sum = label + randNum\n        return image, label, randNum_oneHot, sum\n\n    def __len__(self):\n        return len(self.MNISTDataset)\n\nmnist_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\nMNIST_trainset = torchvision.datasets.MNIST('/tmp', train=True, download=True, transform=mnist_transform)\nMNIST_testset = torchvision.datasets.MNIST('/tmp', train=False, download=True, transform=mnist_transform)\n\ntrain_dataset = RandomMNISTDataset(MNIST_trainset)\ntest_dataset = RandomMNISTDataset(MNIST_testset)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:09.064623Z","iopub.execute_input":"2021-10-13T06:42:09.0654Z","iopub.status.idle":"2021-10-13T06:42:09.109992Z","shell.execute_reply.started":"2021-10-13T06:42:09.06536Z","shell.execute_reply":"2021-10-13T06:42:09.109298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Batch Shape","metadata":{}},{"cell_type":"code","source":"batch = next(iter(train_loader))\n\nimages, labels, randNum, sums = batch\n\nimages.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:09.11146Z","iopub.execute_input":"2021-10-13T06:42:09.111735Z","iopub.status.idle":"2021-10-13T06:42:09.177885Z","shell.execute_reply.started":"2021-10-13T06:42:09.111703Z","shell.execute_reply":"2021-10-13T06:42:09.17711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"randNum[0], sums[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:09.179048Z","iopub.execute_input":"2021-10-13T06:42:09.179391Z","iopub.status.idle":"2021-10-13T06:42:09.188254Z","shell.execute_reply.started":"2021-10-13T06:42:09.179357Z","shell.execute_reply":"2021-10-13T06:42:09.18753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sums.squeeze()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:50:29.339234Z","iopub.execute_input":"2021-10-13T06:50:29.33992Z","iopub.status.idle":"2021-10-13T06:50:29.351683Z","shell.execute_reply.started":"2021-10-13T06:50:29.339882Z","shell.execute_reply":"2021-10-13T06:50:29.350582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualize Batch","metadata":{}},{"cell_type":"code","source":"grid = torchvision.utils.make_grid(images[:30], nrow=10)\nplt.figure(figsize=(15,15))\nplt.imshow(np.transpose(grid, (1,2,0)))\nprint('labels:', labels[:30])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:09.189661Z","iopub.execute_input":"2021-10-13T06:42:09.189918Z","iopub.status.idle":"2021-10-13T06:42:09.490206Z","shell.execute_reply.started":"2021-10-13T06:42:09.189887Z","shell.execute_reply":"2021-10-13T06:42:09.489547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Neural Network","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n        \n        self.fc_rand1 = nn.Linear(in_features = 10, out_features = 20)\n        self.fc1 = nn.Linear(in_features=192+20, out_features=100)\n        self.fc2 = nn.Linear(in_features=100, out_features=60)\n        self.out = nn.Linear(in_features=60, out_features=29)\n    \n    def forward(self, image, randNum):\n        ## Input Layer\n        x = image\n        \n        ## Conv layer 1\n        x = self.conv1(x) ## Input image 28x28x1, Output 24x24x6\n        x = F.relu(x)\n        x = F.max_pool2d(x,kernel_size=2,stride=2) ## Input 24x24x6, Output 12x12x6\n        \n        ## Conv layer 2\n        x = self.conv2(x) ## Input 12x12x6, Output 8x8x12\n        x = F.relu(x)\n        x = F.max_pool2d(x,kernel_size=2,stride=2) ## Input 8x8x12, Output 4x4x12\n        \n        ## Reshape\n        x = x.reshape(-1, 12*4*4)\n        \n        ## Process random number\n        y = randNum.type(torch.float32)\n        ## Pass one hot encoded random number through fully connected layer 10>20 neurons\n        y = self.fc_rand1(y)\n        y = F.relu(y)\n        y = y.reshape(-1, 20)\n        \n        ## Concatenate MNIST convolution output with Random Number fc output\n        x1 = torch.cat((x, y), dim = 1)\n        \n        ## Fully connected layers\n        x1 = self.fc1(x1)\n        x1 = F.relu(x1)\n        \n        x1 = self.fc2(x1)\n        x1 = F.relu(x1)\n        x1 = self.out(x1)\n        \n        #print(x1.shape)\n        mnist_output = F.softmax(x1[:,0:10], dim = 0)\n        sum_output = F.softmax(x1[:,10:], dim = 0)\n        \n        return mnist_output, sum_output","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:10:16.304091Z","iopub.execute_input":"2021-10-13T07:10:16.304892Z","iopub.status.idle":"2021-10-13T07:10:16.317328Z","shell.execute_reply.started":"2021-10-13T07:10:16.304845Z","shell.execute_reply":"2021-10-13T07:10:16.31619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Summary","metadata":{}},{"cell_type":"code","source":"model = Net().to(device)\nsummary(model, [(1,28, 28),(1,1,10)])\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:09.505282Z","iopub.execute_input":"2021-10-13T06:42:09.505586Z","iopub.status.idle":"2021-10-13T06:42:11.903418Z","shell.execute_reply.started":"2021-10-13T06:42:09.505552Z","shell.execute_reply":"2021-10-13T06:42:11.90271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = torch.randint(0,9,(1,1))\nprint(test[0,0:10])\ntest1 = F.one_hot(test, num_classes =10)\nprint(test1)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:11.906044Z","iopub.execute_input":"2021-10-13T06:42:11.906272Z","iopub.status.idle":"2021-10-13T06:42:11.914607Z","shell.execute_reply.started":"2021-10-13T06:42:11.906237Z","shell.execute_reply":"2021-10-13T06:42:11.913165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels, randNum, sums = images.to(device), labels.to(device), randNum.to(device), sums.to(device)\nmnist_pred, sum_pred = model(images, randNum)\nmnist_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:10:23.908922Z","iopub.execute_input":"2021-10-13T07:10:23.909733Z","iopub.status.idle":"2021-10-13T07:10:23.923584Z","shell.execute_reply.started":"2021-10-13T07:10:23.909695Z","shell.execute_reply":"2021-10-13T07:10:23.922726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_pred.shape, sum_pred.shape ## Shapes of outputs are defined by batch size","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:10:32.783659Z","iopub.execute_input":"2021-10-13T07:10:32.785334Z","iopub.status.idle":"2021-10-13T07:10:32.796072Z","shell.execute_reply.started":"2021-10-13T07:10:32.785285Z","shell.execute_reply":"2021-10-13T07:10:32.795132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_pred[0].sum() ## Each row must sum to 1, considering softmax function has been applied to equate values to probabilities","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:10:38.910769Z","iopub.execute_input":"2021-10-13T07:10:38.911036Z","iopub.status.idle":"2021-10-13T07:10:38.921444Z","shell.execute_reply.started":"2021-10-13T07:10:38.911008Z","shell.execute_reply":"2021-10-13T07:10:38.920354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Train & Test Functions","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\ntorch.set_grad_enabled(True)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T06:42:11.965348Z","iopub.execute_input":"2021-10-13T06:42:11.965757Z","iopub.status.idle":"2021-10-13T06:42:11.972077Z","shell.execute_reply.started":"2021-10-13T06:42:11.965722Z","shell.execute_reply":"2021-10-13T06:42:11.971336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Define training function\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    pbar = tqdm(train_loader)\n    for batch_idx, (images, labels, randNum, sums) in enumerate(pbar):\n        images, labels, randNum, sums = images.to(device), labels.to(device), randNum.to(device), sums.to(device)\n        ## Zero out all gradients to prevent accumulation\n        optimizer.zero_grad()\n        ## Forward pass\n        mnist_output, sum_output = model(images, randNum)\n        \n        ## Calculate loss\n        MNIST_loss = F.cross_entropy(mnist_output, labels)\n        sum_loss = F.cross_entropy(sum_output, sums.squeeze())\n        loss = (MNIST_loss + sum_loss)\n        \n        ## Backpropagation\n        loss.backward()\n        optimizer.step()\n        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:15:45.629896Z","iopub.execute_input":"2021-10-13T07:15:45.630151Z","iopub.status.idle":"2021-10-13T07:15:45.638294Z","shell.execute_reply.started":"2021-10-13T07:15:45.630124Z","shell.execute_reply":"2021-10-13T07:15:45.637416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_num_correct(preds, labels):\n    return preds.argmax(dim=1).eq(labels).sum().item()\n\n## Define testing function\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss, mnist_test_loss, sums_test_loss  = 0, 0, 0\n    correct_mnist, correct_sums = 0, 0\n    \n    with torch.no_grad():\n        for images, labels, randNum, sums in test_loader:\n            \n            images, labels, randNum, sums = images.to(device), labels.to(device), randNum.to(device), sums.to(device)\n            ## Forward pass\n            mnist_output, sum_output = model(images, randNum)\n            \n            ## Calculate loss\n            mnist_test_loss += F.cross_entropy(mnist_output, labels, reduction='sum').item()  \n            sums_test_loss += F.cross_entropy(sum_output, sums.squeeze(), reduction='sum').item()\n            \n            correct_mnist = get_num_correct(mnist_output, labels)\n\n            correct_sums = get_num_correct(sum_output, sums.squeeze())\n\n    test_loss = mnist_test_loss + sums_test_loss\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average MNIST loss: {:.4f}, MNIST_Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        mnist_test_loss, correct_mnist, len(test_loader.dataset),\n        100. * correct_mnist / len(test_loader.dataset)))\n    \n    print('\\nTest set: Average SUM loss: {:.4f}, SUM_Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        sums_test_loss, correct_sums, len(test_loader.dataset),\n        100. * correct_sums / len(test_loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:15:54.038628Z","iopub.execute_input":"2021-10-13T07:15:54.038898Z","iopub.status.idle":"2021-10-13T07:15:54.050558Z","shell.execute_reply.started":"2021-10-13T07:15:54.03887Z","shell.execute_reply":"2021-10-13T07:15:54.048307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train & Test Network","metadata":{}},{"cell_type":"code","source":"model = Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\nepochs = 30\nfor epoch in range(1, epochs):\n    train(model, device, train_loader, optimizer, epoch)\n    test(model, device, test_loader)\n    \n'''\nNeural network is unable to learn because of random number FC output being added to MNIST convolution ouput and then being\npassed through a series of fully connected layers. \nLack of a discernible pattern with the random numbers generated leads to the sum output being random as well; with the neural\nnetwork having no specific pattern/characteristics/properties to learn and exploit to create a reliable prediction.\n'''","metadata":{"execution":{"iopub.status.busy":"2021-10-13T07:16:07.334575Z","iopub.execute_input":"2021-10-13T07:16:07.335308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}